{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, Conv2DTranspose, Concatenate, BatchNormalization, UpSampling2D, LeakyReLU\n",
    "from tensorflow.keras.layers import  Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import random\n",
    "import cv2\n",
    "from random import shuffle\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "def dataload():\n",
    "    img = np.load(\"imgs.npy\")\n",
    "    mask = np.load(\"masks.npy\")\n",
    "    \n",
    "    # shuffle\n",
    "    shuffle = np.arange(img.shape[0])\n",
    "    np.random.shuffle(shuffle)\n",
    "    img = img[shuffle]\n",
    "    mask = mask[shuffle]\n",
    "\n",
    "    img = np.expand_dims(img, axis=-1)\n",
    "    mask = np.expand_dims(mask, axis=-1) \n",
    "#     mask = to_categorical(mask) \n",
    "    \n",
    "    return img, mask \n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    yt0 = y_true[:,:,:,0]\n",
    "    yp0 = K.cast(y_pred[:,:,:,0] > 0.5, 'float32')\n",
    "    inter = tf.math.count_nonzero(tf.logical_and(tf.equal(yt0, 1), tf.equal(yp0, 1)))\n",
    "    union = tf.math.count_nonzero(tf.add(yt0, yp0))\n",
    "    iou = tf.where(tf.equal(union, 0), 1., tf.cast(inter/union, 'float32'))\n",
    "    return iou\n",
    "\n",
    "# def minmaxScaler(data):\n",
    "\n",
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "#     y_true = y_true[:,:,:,0]\n",
    "\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.cast(y_true_f, 'float32')\n",
    "    y_pred_f = K.cast(y_pred_f, 'float32')\n",
    "\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "#     y_pred_c = K.cast(y_pred_f > 0, 'float32')\n",
    "#     y_true_c = K.cast(y_true_f > 0, 'float32')\n",
    "#     intersection = K.sum(K.cast(y_pred_f == y_true_f, 'float32'))\n",
    "    \n",
    "#     return (2. * intersection + smooth) / (K.sum(y_true_c) + K.sum(y_pred_c) + smooth)\n",
    "\n",
    "def dice_coef_multilabel(y_true, y_pred, numLabels=3):\n",
    "    dice = 0\n",
    "    \n",
    "    for index in range(numLabels):\n",
    "        if index == 0: continue\n",
    "        y_true_i = K.cast(K.equal(y_true, index), 'float32')\n",
    "        dice += dice_coef(y_true_i, y_pred)\n",
    "        \n",
    "    return dice / (numLabels - 1) # taking average\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    y_pred = K.argmax(y_pred, axis=-1)\n",
    "    y_true = y_true[:,:,:,1]\n",
    "    \n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    y_true_f = K.cast(y_true_f, 'float32')\n",
    "    y_pred_f = K.cast(y_pred_f, 'float32')\n",
    "    \n",
    "    intersection = y_true_f * y_pred_f\n",
    "    score = (2. * K.sum(intersection) + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "    return tf.math.exp(1  - score) - 1.0\n",
    "    # return 1. - score\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return categorical_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "\n",
    "def build_unet(sz=(512,512,1)):\n",
    "    x = Input(sz)\n",
    "    inputs = x\n",
    "  \n",
    "    #down sampling \n",
    "    f = 8\n",
    "    layers = []\n",
    "  \n",
    "    for i in range(0, 6):\n",
    "        x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "        x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "        layers.append(x)\n",
    "        x = MaxPooling2D() (x)\n",
    "        f = f*2\n",
    "        ff2 = 64 \n",
    "    \n",
    "    #bottleneck \n",
    "    j = len(layers) - 1\n",
    "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n",
    "    x = Concatenate(axis=3)([x, layers[j]])\n",
    "    j = j -1 \n",
    "  \n",
    "    #upsampling \n",
    "    for i in range(0, 5):\n",
    "        ff2 = ff2//2\n",
    "        f = f // 2 \n",
    "        x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "        x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "        x = Conv2DTranspose(ff2, 2, strides=(2, 2), padding='same') (x)\n",
    "        x = Concatenate(axis=3)([x, layers[j]])\n",
    "        j = j -1 \n",
    "    \n",
    "  \n",
    "    #classification \n",
    "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "    x = Conv2D(f, 3, activation='relu', padding='same') (x)\n",
    "    outputs = Conv2D(3, 1, activation='softmax') (x)\n",
    "    \n",
    "    #model creation \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = [dice_coef_multilabel])\n",
    "  \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3890, 512, 512, 1) (3890, 512, 512, 1)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 512, 512, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 512, 512, 8)  80          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 8)  584         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 256, 256, 8)  0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 16) 1168        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 16) 2320        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 32) 9248        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 128)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 16, 16, 256)  295168      max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 8, 8, 256)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 512)    1180160     max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 8, 512)    2359808     conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 64)   131136      conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 16, 16, 320)  0           conv2d_transpose[0][0]           \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  737536      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  590080      conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 32, 32, 32)   32800       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 160)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 128)  184448      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 64, 64, 16)   8208        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 80)   0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 64)   46144       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 128, 128, 8)  2056        conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 40) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 128, 128, 32) 11552       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 256, 256, 4)  516         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 20) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 256, 256, 16) 2896        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 512, 512, 2)  130         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512, 512, 10) 0           conv2d_transpose_5[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 512, 512, 16) 1456        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 512, 512, 16) 2320        conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 512, 512, 3)  51          conv2d_25[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,667,529\n",
      "Trainable params: 6,667,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "219/219 [==============================] - 55s 249ms/step - loss: 0.1069 - dice_coef_multilabel: 0.2279 - val_loss: 0.0546 - val_dice_coef_multilabel: 0.3126\n",
      "Epoch 2/500\n",
      "219/219 [==============================] - 52s 237ms/step - loss: 0.0341 - dice_coef_multilabel: 0.6196 - val_loss: 0.0316 - val_dice_coef_multilabel: 0.5231\n",
      "Epoch 3/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0130 - dice_coef_multilabel: 0.7083 - val_loss: 0.0234 - val_dice_coef_multilabel: 0.4954\n",
      "Epoch 4/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0095 - dice_coef_multilabel: 0.7187 - val_loss: 0.0211 - val_dice_coef_multilabel: 0.8606\n",
      "Epoch 5/500\n",
      "219/219 [==============================] - 52s 235ms/step - loss: 0.0082 - dice_coef_multilabel: 0.7199 - val_loss: 0.0240 - val_dice_coef_multilabel: 0.8609\n",
      "Epoch 6/500\n",
      "219/219 [==============================] - 51s 235ms/step - loss: 0.0073 - dice_coef_multilabel: 0.7235 - val_loss: 0.0285 - val_dice_coef_multilabel: 0.8582\n",
      "Epoch 7/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0065 - dice_coef_multilabel: 0.7232 - val_loss: 0.0244 - val_dice_coef_multilabel: 0.8620\n",
      "Epoch 8/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0067 - dice_coef_multilabel: 0.7228 - val_loss: 0.0174 - val_dice_coef_multilabel: 0.8610\n",
      "Epoch 9/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0061 - dice_coef_multilabel: 0.7235 - val_loss: 0.0309 - val_dice_coef_multilabel: 0.8511\n",
      "Epoch 10/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0592 - dice_coef_multilabel: 0.4643 - val_loss: 0.0296 - val_dice_coef_multilabel: 0.8097\n",
      "Epoch 11/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0153 - dice_coef_multilabel: 0.7126 - val_loss: 0.0179 - val_dice_coef_multilabel: 0.7453\n",
      "Epoch 12/500\n",
      "219/219 [==============================] - 52s 237ms/step - loss: 0.0091 - dice_coef_multilabel: 0.7215 - val_loss: 0.0187 - val_dice_coef_multilabel: 0.8362\n",
      "Epoch 13/500\n",
      "219/219 [==============================] - 52s 239ms/step - loss: 0.0079 - dice_coef_multilabel: 0.7195 - val_loss: 0.0170 - val_dice_coef_multilabel: 0.8343\n",
      "Epoch 14/500\n",
      "219/219 [==============================] - 52s 237ms/step - loss: 0.0073 - dice_coef_multilabel: 0.7235 - val_loss: 0.0144 - val_dice_coef_multilabel: 0.8658\n",
      "Epoch 15/500\n",
      "219/219 [==============================] - 52s 235ms/step - loss: 0.0064 - dice_coef_multilabel: 0.7225 - val_loss: 0.0136 - val_dice_coef_multilabel: 0.8657\n",
      "Epoch 16/500\n",
      "219/219 [==============================] - 51s 235ms/step - loss: 0.0060 - dice_coef_multilabel: 0.7241 - val_loss: 0.0137 - val_dice_coef_multilabel: 0.8659\n",
      "Epoch 17/500\n",
      "219/219 [==============================] - 52s 237ms/step - loss: 0.0057 - dice_coef_multilabel: 0.7265 - val_loss: 0.0155 - val_dice_coef_multilabel: 0.8643\n",
      "Epoch 18/500\n",
      "219/219 [==============================] - 52s 237ms/step - loss: 0.0056 - dice_coef_multilabel: 0.7247 - val_loss: 0.0126 - val_dice_coef_multilabel: 0.8666\n",
      "Epoch 19/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0051 - dice_coef_multilabel: 0.7270 - val_loss: 0.0141 - val_dice_coef_multilabel: 0.8674\n",
      "Epoch 20/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0051 - dice_coef_multilabel: 0.7264 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.8659\n",
      "Epoch 21/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0051 - dice_coef_multilabel: 0.7254 - val_loss: 0.0106 - val_dice_coef_multilabel: 0.8669\n",
      "Epoch 22/500\n",
      "219/219 [==============================] - 52s 236ms/step - loss: 0.0048 - dice_coef_multilabel: 0.7270 - val_loss: 0.0111 - val_dice_coef_multilabel: 0.8685\n",
      "Epoch 23/500\n",
      "219/219 [==============================] - 52s 236ms/step - loss: 0.0047 - dice_coef_multilabel: 0.7273 - val_loss: 0.0101 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 24/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0045 - dice_coef_multilabel: 0.7274 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 25/500\n",
      "219/219 [==============================] - 52s 236ms/step - loss: 0.0141 - dice_coef_multilabel: 0.7064 - val_loss: 0.0157 - val_dice_coef_multilabel: 0.7042\n",
      "Epoch 26/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0079 - dice_coef_multilabel: 0.7208 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.7869\n",
      "Epoch 27/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0057 - dice_coef_multilabel: 0.7259 - val_loss: 0.0142 - val_dice_coef_multilabel: 0.7926\n",
      "Epoch 28/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0051 - dice_coef_multilabel: 0.7264 - val_loss: 0.0126 - val_dice_coef_multilabel: 0.8280\n",
      "Epoch 29/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0050 - dice_coef_multilabel: 0.7280 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 30/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0046 - dice_coef_multilabel: 0.7285 - val_loss: 0.0133 - val_dice_coef_multilabel: 0.8671\n",
      "Epoch 31/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0046 - dice_coef_multilabel: 0.7271 - val_loss: 0.0107 - val_dice_coef_multilabel: 0.8679\n",
      "Epoch 32/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0044 - dice_coef_multilabel: 0.7280 - val_loss: 0.0136 - val_dice_coef_multilabel: 0.8681\n",
      "Epoch 33/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0047 - dice_coef_multilabel: 0.7300 - val_loss: 0.0151 - val_dice_coef_multilabel: 0.8683\n",
      "Epoch 34/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0055 - dice_coef_multilabel: 0.7270 - val_loss: 0.0116 - val_dice_coef_multilabel: 0.7885\n",
      "Epoch 35/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0047 - dice_coef_multilabel: 0.7279 - val_loss: 0.0153 - val_dice_coef_multilabel: 0.8659\n",
      "Epoch 36/500\n",
      "219/219 [==============================] - 52s 235ms/step - loss: 0.0050 - dice_coef_multilabel: 0.7262 - val_loss: 0.0111 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 37/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0043 - dice_coef_multilabel: 0.7275 - val_loss: 0.0101 - val_dice_coef_multilabel: 0.8676\n",
      "Epoch 38/500\n",
      "219/219 [==============================] - 52s 236ms/step - loss: 0.0045 - dice_coef_multilabel: 0.7295 - val_loss: 0.0102 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 39/500\n",
      "219/219 [==============================] - 52s 238ms/step - loss: 0.0046 - dice_coef_multilabel: 0.7279 - val_loss: 0.0111 - val_dice_coef_multilabel: 0.8665\n",
      "Epoch 40/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0042 - dice_coef_multilabel: 0.7267 - val_loss: 0.0137 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 41/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0040 - dice_coef_multilabel: 0.7290 - val_loss: 0.0114 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 42/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0039 - dice_coef_multilabel: 0.7303 - val_loss: 0.0129 - val_dice_coef_multilabel: 0.8681\n",
      "Epoch 43/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0038 - dice_coef_multilabel: 0.7293 - val_loss: 0.0107 - val_dice_coef_multilabel: 0.8676\n",
      "Epoch 44/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0038 - dice_coef_multilabel: 0.7298 - val_loss: 0.0122 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 45/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0040 - dice_coef_multilabel: 0.7271 - val_loss: 0.0134 - val_dice_coef_multilabel: 0.8682\n",
      "Epoch 46/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0037 - dice_coef_multilabel: 0.7280 - val_loss: 0.0122 - val_dice_coef_multilabel: 0.8665\n",
      "Epoch 47/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0039 - dice_coef_multilabel: 0.7280 - val_loss: 0.0110 - val_dice_coef_multilabel: 0.8685\n",
      "Epoch 48/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0044 - dice_coef_multilabel: 0.7298 - val_loss: 0.0111 - val_dice_coef_multilabel: 0.8697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0107 - dice_coef_multilabel: 0.7164 - val_loss: 0.0128 - val_dice_coef_multilabel: 0.8678\n",
      "Epoch 50/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0054 - dice_coef_multilabel: 0.7267 - val_loss: 0.0121 - val_dice_coef_multilabel: 0.8676\n",
      "Epoch 51/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0045 - dice_coef_multilabel: 0.7273 - val_loss: 0.0119 - val_dice_coef_multilabel: 0.8675\n",
      "Epoch 52/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0041 - dice_coef_multilabel: 0.7290 - val_loss: 0.0140 - val_dice_coef_multilabel: 0.8675\n",
      "Epoch 53/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0039 - dice_coef_multilabel: 0.7302 - val_loss: 0.0121 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 54/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0039 - dice_coef_multilabel: 0.7291 - val_loss: 0.0127 - val_dice_coef_multilabel: 0.8679\n",
      "Epoch 55/500\n",
      "219/219 [==============================] - 51s 235ms/step - loss: 0.0039 - dice_coef_multilabel: 0.7296 - val_loss: 0.0146 - val_dice_coef_multilabel: 0.8670\n",
      "Epoch 56/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0037 - dice_coef_multilabel: 0.7294 - val_loss: 0.0115 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 57/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0043 - dice_coef_multilabel: 0.7305 - val_loss: 0.0113 - val_dice_coef_multilabel: 0.8272\n",
      "Epoch 58/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0044 - dice_coef_multilabel: 0.7258 - val_loss: 0.0132 - val_dice_coef_multilabel: 0.8674\n",
      "Epoch 59/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0038 - dice_coef_multilabel: 0.7322 - val_loss: 0.0156 - val_dice_coef_multilabel: 0.8669\n",
      "Epoch 60/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0040 - dice_coef_multilabel: 0.7314 - val_loss: 0.0123 - val_dice_coef_multilabel: 0.8689\n",
      "Epoch 61/500\n",
      "219/219 [==============================] - 51s 235ms/step - loss: 0.0036 - dice_coef_multilabel: 0.7319 - val_loss: 0.0109 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 62/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0035 - dice_coef_multilabel: 0.7300 - val_loss: 0.0127 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 63/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7311 - val_loss: 0.0112 - val_dice_coef_multilabel: 0.8679\n",
      "Epoch 64/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7289 - val_loss: 0.0126 - val_dice_coef_multilabel: 0.8294\n",
      "Epoch 65/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7316 - val_loss: 0.0127 - val_dice_coef_multilabel: 0.8692\n",
      "Epoch 66/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0036 - dice_coef_multilabel: 0.7296 - val_loss: 0.0149 - val_dice_coef_multilabel: 0.8685\n",
      "Epoch 67/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7291 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.8682\n",
      "Epoch 68/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0033 - dice_coef_multilabel: 0.7317 - val_loss: 0.0144 - val_dice_coef_multilabel: 0.8286\n",
      "Epoch 69/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7278 - val_loss: 0.0127 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 70/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7305 - val_loss: 0.0123 - val_dice_coef_multilabel: 0.8683\n",
      "Epoch 71/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0032 - dice_coef_multilabel: 0.7287 - val_loss: 0.0129 - val_dice_coef_multilabel: 0.8683\n",
      "Epoch 72/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0031 - dice_coef_multilabel: 0.7307 - val_loss: 0.0138 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 73/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0032 - dice_coef_multilabel: 0.7292 - val_loss: 0.0115 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 74/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7297 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.8681\n",
      "Epoch 75/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0031 - dice_coef_multilabel: 0.7306 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 76/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0031 - dice_coef_multilabel: 0.7301 - val_loss: 0.0151 - val_dice_coef_multilabel: 0.8285\n",
      "Epoch 77/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0031 - dice_coef_multilabel: 0.7306 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.7883\n",
      "Epoch 78/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0101 - dice_coef_multilabel: 0.7170 - val_loss: 0.0113 - val_dice_coef_multilabel: 0.7906\n",
      "Epoch 79/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0051 - dice_coef_multilabel: 0.7277 - val_loss: 0.0105 - val_dice_coef_multilabel: 0.8295\n",
      "Epoch 80/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0040 - dice_coef_multilabel: 0.7280 - val_loss: 0.0116 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 81/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0036 - dice_coef_multilabel: 0.7297 - val_loss: 0.0117 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 82/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7315 - val_loss: 0.0109 - val_dice_coef_multilabel: 0.8682\n",
      "Epoch 83/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0032 - dice_coef_multilabel: 0.7333 - val_loss: 0.0123 - val_dice_coef_multilabel: 0.8689\n",
      "Epoch 84/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0031 - dice_coef_multilabel: 0.7334 - val_loss: 0.0127 - val_dice_coef_multilabel: 0.8682\n",
      "Epoch 85/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7317 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.8683\n",
      "Epoch 86/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7301 - val_loss: 0.0128 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 87/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7331 - val_loss: 0.0130 - val_dice_coef_multilabel: 0.8689\n",
      "Epoch 88/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0029 - dice_coef_multilabel: 0.7326 - val_loss: 0.0147 - val_dice_coef_multilabel: 0.8689\n",
      "Epoch 89/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0029 - dice_coef_multilabel: 0.7328 - val_loss: 0.0123 - val_dice_coef_multilabel: 0.8681\n",
      "Epoch 90/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7325 - val_loss: 0.0137 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 91/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0029 - dice_coef_multilabel: 0.7320 - val_loss: 0.0127 - val_dice_coef_multilabel: 0.8687\n",
      "Epoch 92/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0028 - dice_coef_multilabel: 0.7319 - val_loss: 0.0124 - val_dice_coef_multilabel: 0.8685\n",
      "Epoch 93/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0028 - dice_coef_multilabel: 0.7310 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.8687\n",
      "Epoch 94/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0028 - dice_coef_multilabel: 0.7315 - val_loss: 0.0138 - val_dice_coef_multilabel: 0.7938\n",
      "Epoch 95/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0028 - dice_coef_multilabel: 0.7290 - val_loss: 0.0143 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 96/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7319 - val_loss: 0.0126 - val_dice_coef_multilabel: 0.8684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0036 - dice_coef_multilabel: 0.7319 - val_loss: 0.0109 - val_dice_coef_multilabel: 0.7862\n",
      "Epoch 98/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0053 - dice_coef_multilabel: 0.7253 - val_loss: 0.0108 - val_dice_coef_multilabel: 0.8289\n",
      "Epoch 99/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0037 - dice_coef_multilabel: 0.7293 - val_loss: 0.0109 - val_dice_coef_multilabel: 0.8286\n",
      "Epoch 100/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0030 - dice_coef_multilabel: 0.7305 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 101/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0028 - dice_coef_multilabel: 0.7311 - val_loss: 0.0129 - val_dice_coef_multilabel: 0.8684\n",
      "Epoch 102/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0027 - dice_coef_multilabel: 0.7337 - val_loss: 0.0132 - val_dice_coef_multilabel: 0.8685\n",
      "Epoch 103/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0026 - dice_coef_multilabel: 0.7323 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.7891\n",
      "Epoch 104/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0026 - dice_coef_multilabel: 0.7320 - val_loss: 0.0125 - val_dice_coef_multilabel: 0.8293\n",
      "Epoch 105/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7318 - val_loss: 0.0132 - val_dice_coef_multilabel: 0.8687\n",
      "Epoch 106/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7348 - val_loss: 0.0143 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 107/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7326 - val_loss: 0.0140 - val_dice_coef_multilabel: 0.8687\n",
      "Epoch 108/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0026 - dice_coef_multilabel: 0.7337 - val_loss: 0.0142 - val_dice_coef_multilabel: 0.8687\n",
      "Epoch 109/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7342 - val_loss: 0.0148 - val_dice_coef_multilabel: 0.8685\n",
      "Epoch 110/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7334 - val_loss: 0.0145 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 111/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7331 - val_loss: 0.0130 - val_dice_coef_multilabel: 0.7902\n",
      "Epoch 112/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0024 - dice_coef_multilabel: 0.7312 - val_loss: 0.0147 - val_dice_coef_multilabel: 0.8689\n",
      "Epoch 113/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0025 - dice_coef_multilabel: 0.7325 - val_loss: 0.0139 - val_dice_coef_multilabel: 0.8692\n",
      "Epoch 114/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0024 - dice_coef_multilabel: 0.7335 - val_loss: 0.0142 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 115/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0024 - dice_coef_multilabel: 0.7327 - val_loss: 0.0138 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 116/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0024 - dice_coef_multilabel: 0.7316 - val_loss: 0.0137 - val_dice_coef_multilabel: 0.8684\n",
      "Epoch 117/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7337 - val_loss: 0.0147 - val_dice_coef_multilabel: 0.8290\n",
      "Epoch 118/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7336 - val_loss: 0.0128 - val_dice_coef_multilabel: 0.8285\n",
      "Epoch 119/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7318 - val_loss: 0.0147 - val_dice_coef_multilabel: 0.8288\n",
      "Epoch 120/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7314 - val_loss: 0.0140 - val_dice_coef_multilabel: 0.8287\n",
      "Epoch 121/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7340 - val_loss: 0.0138 - val_dice_coef_multilabel: 0.7902\n",
      "Epoch 122/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7313 - val_loss: 0.0148 - val_dice_coef_multilabel: 0.7892\n",
      "Epoch 123/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7320 - val_loss: 0.0141 - val_dice_coef_multilabel: 0.7890\n",
      "Epoch 124/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0022 - dice_coef_multilabel: 0.7323 - val_loss: 0.0135 - val_dice_coef_multilabel: 0.8686\n",
      "Epoch 125/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7327 - val_loss: 0.0148 - val_dice_coef_multilabel: 0.8288\n",
      "Epoch 126/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0022 - dice_coef_multilabel: 0.7335 - val_loss: 0.0132 - val_dice_coef_multilabel: 0.8305\n",
      "Epoch 127/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7347 - val_loss: 0.0145 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 128/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7329 - val_loss: 0.0145 - val_dice_coef_multilabel: 0.8310\n",
      "Epoch 129/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0022 - dice_coef_multilabel: 0.7312 - val_loss: 0.0170 - val_dice_coef_multilabel: 0.8691\n",
      "Epoch 130/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0023 - dice_coef_multilabel: 0.7342 - val_loss: 0.0144 - val_dice_coef_multilabel: 0.8688\n",
      "Epoch 131/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0021 - dice_coef_multilabel: 0.7333 - val_loss: 0.0151 - val_dice_coef_multilabel: 0.8286\n",
      "Epoch 132/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0021 - dice_coef_multilabel: 0.7349 - val_loss: 0.0131 - val_dice_coef_multilabel: 0.8291\n",
      "Epoch 133/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0020 - dice_coef_multilabel: 0.7344 - val_loss: 0.0161 - val_dice_coef_multilabel: 0.8690\n",
      "Epoch 134/500\n",
      "219/219 [==============================] - 51s 232ms/step - loss: 0.0020 - dice_coef_multilabel: 0.7353 - val_loss: 0.0152 - val_dice_coef_multilabel: 0.7888\n",
      "Epoch 135/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0021 - dice_coef_multilabel: 0.7346 - val_loss: 0.0150 - val_dice_coef_multilabel: 0.7097\n",
      "Epoch 136/500\n",
      "219/219 [==============================] - 51s 233ms/step - loss: 0.0021 - dice_coef_multilabel: 0.7320 - val_loss: 0.0185 - val_dice_coef_multilabel: 0.7482\n",
      "Epoch 137/500\n",
      "219/219 [==============================] - 51s 235ms/step - loss: 0.0094 - dice_coef_multilabel: 0.7174 - val_loss: 0.0158 - val_dice_coef_multilabel: 0.8671\n",
      "Epoch 138/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0051 - dice_coef_multilabel: 0.7284 - val_loss: 0.0123 - val_dice_coef_multilabel: 0.8684\n",
      "Epoch 139/500\n",
      "219/219 [==============================] - 51s 234ms/step - loss: 0.0039 - dice_coef_multilabel: 0.7272 - val_loss: 0.0114 - val_dice_coef_multilabel: 0.8675\n",
      "Epoch 140/500\n",
      "219/219 [==============================] - 52s 238ms/step - loss: 0.0034 - dice_coef_multilabel: 0.7294 - val_loss: 0.0134 - val_dice_coef_multilabel: 0.8680\n",
      "Epoch 141/500\n",
      "219/219 [==============================] - 52s 236ms/step - loss: 0.0031 - dice_coef_multilabel: 0.7316 - val_loss: 0.0190 - val_dice_coef_multilabel: 0.7460\n",
      "Epoch 142/500\n",
      "219/219 [==============================] - 52s 237ms/step - loss: 0.0045 - dice_coef_multilabel: 0.7292 - val_loss: 0.0139 - val_dice_coef_multilabel: 0.8675\n",
      "Epoch 143/500\n",
      "219/219 [==============================] - 52s 238ms/step - loss: 0.0032 - dice_coef_multilabel: 0.7321 - val_loss: 0.0134 - val_dice_coef_multilabel: 0.8679\n",
      "Epoch 144/500\n",
      "192/219 [=========================>....] - ETA: 6s - loss: 0.0028 - dice_coef_multilabel: 0.7335"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-d69553823137>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m         \u001b[0mepoch_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \"\"\"\n\u001b[1;32m    388\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_process_logs\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;34m\"\"\"Turns tensors into numpy arrays or Python scalars.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36mto_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    517\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    959\u001b[0m     \"\"\"\n\u001b[1;32m    960\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "    source, target = dataload()\n",
    "    shuffle = np.arange(source.shape[0])\n",
    "    source = source[shuffle]\n",
    "    target = target[shuffle]\n",
    "    \n",
    "    model = build_unet()\n",
    "    model.summary()\n",
    "\n",
    "    model.fit(source, target, validation_split=0.1, epochs=500, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
